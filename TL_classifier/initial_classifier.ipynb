{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: ...working... done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.4.10\n",
      "  latest version: 4.5.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda/envs/tl-detect\n",
      "\n",
      "  added / updated specs: \n",
      "    - keras\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    h5py-2.7.1                 |           py35_2         3.9 MB  conda-forge\n",
      "    keras-2.1.5                |           py35_0         498 KB  conda-forge\n",
      "    yaml-0.1.7                 |                0         302 KB  conda-forge\n",
      "    pygpu-0.7.5                |           py35_0         1.4 MB  conda-forge\n",
      "    mako-1.0.7                 |           py35_0         115 KB  conda-forge\n",
      "    scipy-1.0.1                |py35_blas_openblas_200        39.4 MB  conda-forge\n",
      "    markupsafe-1.0             |           py35_0          32 KB  conda-forge\n",
      "    theano-1.0.1               |           py35_1         3.7 MB  conda-forge\n",
      "    libgpuarray-0.7.5          |                0         247 KB  conda-forge\n",
      "    pyyaml-3.12                |           py35_1         394 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        50.0 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    h5py:        2.7.1-py35_2                 conda-forge\n",
      "    keras:       2.1.5-py35_0                 conda-forge\n",
      "    libgpuarray: 0.7.5-0                      conda-forge\n",
      "    mako:        1.0.7-py35_0                 conda-forge\n",
      "    markupsafe:  1.0-py35_0                   conda-forge\n",
      "    pygpu:       0.7.5-py35_0                 conda-forge\n",
      "    pyyaml:      3.12-py35_1                  conda-forge\n",
      "    scipy:       1.0.1-py35_blas_openblas_200 conda-forge [blas_openblas]\n",
      "    theano:      1.0.1-py35_1                 conda-forge\n",
      "    yaml:        0.1.7-0                      conda-forge\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    }
   ],
   "source": [
    "!bash -c 'source activate tl-detect && conda install -qy -c conda-forge keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"backend\": \"tensorflow\",\n",
      "    \"image_data_format\": \"channels_last\",\n",
      "    \"epsilon\": 1e-07,\n",
      "    \"floatx\": \"float32\"\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat ~/.keras/keras.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: cannot stat '../imgs/training/bosch/Green': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!cp -R ../imgs/training/bosch/Green ../imgs/training/ && cp -R ../imgs/training/bosch/Red ../imgs/training/ && cp -R ../imgs/training/bosch/Yellow ../imgs/training/  && mv ../imgs/training/bosch ../imgs/bosch_tl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd ../imgs/training && find . -size 0 -exec rm {} \\;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import keras\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 75, 40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNKNOWN = 4\n",
    "GREEN = 2\n",
    "YELLOW = 1\n",
    "RED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(img_path, dim):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        raise ValueError('Couldn\\'t read img: ' + img_path)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    return cv2.resize(hsv, dim, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "def read_color(path, color):\n",
    "    x = np.stack([read_img(path + f, (img_height, img_width)) for f in os.listdir(path)], axis=0)\n",
    "    y = np.full(x.shape[0], color)\n",
    "    return (x, y)\n",
    "\n",
    "train_data_dir = '../imgs/training/'\n",
    "x_train = []\n",
    "y_train = []\n",
    "for directory, color in zip(['Red/', 'Yellow/', 'Green/'], [RED, YELLOW, GREEN]):\n",
    "    x, y = read_color(os.path.join(train_data_dir, directory), color)\n",
    "    x_train.append(x)\n",
    "    y_train.append(y)\n",
    "\n",
    "x_train = np.concatenate(x_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "validation_data_dir = '../imgs/validation/'\n",
    "x_validation = []\n",
    "y_validation = []\n",
    "for directory, color in zip(['Red/', 'Yellow/', 'Green/'], [RED, YELLOW, GREEN]):\n",
    "    x, y = read_color(os.path.join(validation_data_dir, directory), color)\n",
    "    x_validation.append(x)\n",
    "    y_validation.append(y)\n",
    "\n",
    "x_validation = np.concatenate(x_validation)\n",
    "y_validation = np.concatenate(y_validation)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_validation = x_validation.astype('float32')\n",
    "x_train /= 255\n",
    "x_validation /= 255\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_validation = keras.utils.to_categorical(y_validation, NUM_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7246, 75, 40, 3)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7246 samples, validate on 893 samples\n",
      "Epoch 1/25\n",
      "7246/7246 [==============================] - 13s 2ms/step - loss: 0.9693 - acc: 0.5740 - val_loss: 1.1256 - val_acc: 0.3830\n",
      "Epoch 2/25\n",
      "7246/7246 [==============================] - 5s 659us/step - loss: 0.8316 - acc: 0.6105 - val_loss: 1.0584 - val_acc: 0.3830\n",
      "Epoch 3/25\n",
      "7246/7246 [==============================] - 4s 487us/step - loss: 0.8294 - acc: 0.6104 - val_loss: 1.2447 - val_acc: 0.3830\n",
      "Epoch 4/25\n",
      "7246/7246 [==============================] - 4s 486us/step - loss: 0.8213 - acc: 0.6116 - val_loss: 1.2048 - val_acc: 0.3830\n",
      "Epoch 5/25\n",
      "7246/7246 [==============================] - 4s 486us/step - loss: 0.8245 - acc: 0.6115 - val_loss: 1.2796 - val_acc: 0.3830\n",
      "Epoch 6/25\n",
      "7246/7246 [==============================] - 4s 487us/step - loss: 0.8260 - acc: 0.6116 - val_loss: 1.1093 - val_acc: 0.3830\n",
      "Epoch 7/25\n",
      "7246/7246 [==============================] - 4s 487us/step - loss: 0.8227 - acc: 0.6119 - val_loss: 1.1753 - val_acc: 0.3830\n",
      "Epoch 8/25\n",
      "7246/7246 [==============================] - 4s 487us/step - loss: 0.8227 - acc: 0.6116 - val_loss: 1.2149 - val_acc: 0.3830\n",
      "Epoch 9/25\n",
      "7246/7246 [==============================] - 4s 487us/step - loss: 0.8205 - acc: 0.6116 - val_loss: 1.1301 - val_acc: 0.3830\n",
      "Epoch 10/25\n",
      "7246/7246 [==============================] - 4s 488us/step - loss: 0.8218 - acc: 0.6116 - val_loss: 1.1746 - val_acc: 0.3830\n",
      "Epoch 11/25\n",
      "7246/7246 [==============================] - 4s 488us/step - loss: 0.8215 - acc: 0.6116 - val_loss: 1.1985 - val_acc: 0.3830\n",
      "Epoch 12/25\n",
      "7246/7246 [==============================] - 4s 487us/step - loss: 0.8224 - acc: 0.6116 - val_loss: 1.2323 - val_acc: 0.3830\n",
      "Epoch 13/25\n",
      "7246/7246 [==============================] - 4s 488us/step - loss: 0.8160 - acc: 0.6116 - val_loss: 1.1577 - val_acc: 0.3830\n",
      "Epoch 14/25\n",
      "7246/7246 [==============================] - 4s 487us/step - loss: 0.8198 - acc: 0.6116 - val_loss: 1.2252 - val_acc: 0.3830\n",
      "Epoch 15/25\n",
      "7246/7246 [==============================] - 4s 488us/step - loss: 0.8222 - acc: 0.6116 - val_loss: 1.2697 - val_acc: 0.3830\n",
      "Epoch 16/25\n",
      "7246/7246 [==============================] - 4s 488us/step - loss: 0.8210 - acc: 0.6116 - val_loss: 1.2134 - val_acc: 0.3830\n",
      "Epoch 17/25\n",
      "7246/7246 [==============================] - 4s 488us/step - loss: 0.8218 - acc: 0.6116 - val_loss: 1.2292 - val_acc: 0.3830\n",
      "Epoch 18/25\n",
      "7246/7246 [==============================] - 4s 488us/step - loss: 0.8191 - acc: 0.6116 - val_loss: 1.1218 - val_acc: 0.3830\n",
      "Epoch 19/25\n",
      "7246/7246 [==============================] - 4s 489us/step - loss: 0.8209 - acc: 0.6116 - val_loss: 1.1814 - val_acc: 0.3830\n",
      "Epoch 20/25\n",
      "7246/7246 [==============================] - 4s 488us/step - loss: 0.8182 - acc: 0.6116 - val_loss: 1.1327 - val_acc: 0.3830\n",
      "Epoch 21/25\n",
      "7246/7246 [==============================] - 4s 489us/step - loss: 0.8193 - acc: 0.6116 - val_loss: 1.2141 - val_acc: 0.3830\n",
      "Epoch 22/25\n",
      "7246/7246 [==============================] - 4s 489us/step - loss: 0.8183 - acc: 0.6116 - val_loss: 1.2372 - val_acc: 0.3830\n",
      "Epoch 23/25\n",
      "7246/7246 [==============================] - 4s 490us/step - loss: 0.8149 - acc: 0.6116 - val_loss: 1.2061 - val_acc: 0.3830\n",
      "Epoch 24/25\n",
      "7246/7246 [==============================] - 4s 490us/step - loss: 0.8165 - acc: 0.6116 - val_loss: 1.1820 - val_acc: 0.3830\n",
      "Epoch 25/25\n",
      "7246/7246 [==============================] - 4s 489us/step - loss: 0.8142 - acc: 0.6116 - val_loss: 1.2061 - val_acc: 0.3830\n",
      "Test loss: 1.2060579320484688\n",
      "Test accuracy: 0.3829787234042553\n"
     ]
    }
   ],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 3, img_width, img_height)\n",
    "    x_validation = x_validation.reshape(x_validation.shape[0], 3, img_width, img_height)\n",
    "    input_shape = (3, img_width, img_heigth)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_width, img_height, 3)\n",
    "    x_validation = x_validation.reshape(x_validation.shape[0], img_width, img_height, 3)\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "    \n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_validation, y_validation))\n",
    "score = model.evaluate(x_validation, y_validation, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
