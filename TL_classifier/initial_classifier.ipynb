{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: ...working... done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.4.10\n",
      "  latest version: 4.5.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda/envs/tl-detect\n",
      "\n",
      "  added / updated specs: \n",
      "    - keras\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    h5py-2.7.1                 |           py35_2         3.9 MB  conda-forge\n",
      "    keras-2.1.5                |           py35_0         498 KB  conda-forge\n",
      "    yaml-0.1.7                 |                0         302 KB  conda-forge\n",
      "    pygpu-0.7.5                |           py35_0         1.4 MB  conda-forge\n",
      "    mako-1.0.7                 |           py35_0         115 KB  conda-forge\n",
      "    scipy-1.0.1                |py35_blas_openblas_200        39.4 MB  conda-forge\n",
      "    markupsafe-1.0             |           py35_0          32 KB  conda-forge\n",
      "    theano-1.0.1               |           py35_1         3.7 MB  conda-forge\n",
      "    libgpuarray-0.7.5          |                0         247 KB  conda-forge\n",
      "    pyyaml-3.12                |           py35_1         394 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        50.0 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    h5py:        2.7.1-py35_2                 conda-forge\n",
      "    keras:       2.1.5-py35_0                 conda-forge\n",
      "    libgpuarray: 0.7.5-0                      conda-forge\n",
      "    mako:        1.0.7-py35_0                 conda-forge\n",
      "    markupsafe:  1.0-py35_0                   conda-forge\n",
      "    pygpu:       0.7.5-py35_0                 conda-forge\n",
      "    pyyaml:      3.12-py35_1                  conda-forge\n",
      "    scipy:       1.0.1-py35_blas_openblas_200 conda-forge [blas_openblas]\n",
      "    theano:      1.0.1-py35_1                 conda-forge\n",
      "    yaml:        0.1.7-0                      conda-forge\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    }
   ],
   "source": [
    "!bash -c 'source activate tl-detect && conda install -qy -c conda-forge keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"backend\": \"tensorflow\",\n",
      "    \"image_data_format\": \"channels_last\",\n",
      "    \"epsilon\": 1e-07,\n",
      "    \"floatx\": \"float32\"\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat ~/.keras/keras.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: cannot stat '../imgs/training/bosch/Green': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!cp -R ../imgs/training/bosch/Green ../imgs/training/ && cp -R ../imgs/training/bosch/Red ../imgs/training/ && cp -R ../imgs/training/bosch/Yellow ../imgs/training/  && mv ../imgs/training/bosch ../imgs/bosch_tl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd ../imgs/training && find . -size 0 -exec rm {} \\;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import keras\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 75, 40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNKNOWN = 4\n",
    "GREEN = 2\n",
    "YELLOW = 1\n",
    "RED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(img_path, dim, colspace = 'BGR'):\n",
    "    if colspace != 'GRAY':\n",
    "        img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        raise ValueError('Couldn\\'t read img: ' + img_path)\n",
    "    if colspace == 'HSV':\n",
    "        logging\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "    return cv2.resize(img, dim, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "def read_color(path, color, dim, colspace):\n",
    "    x = np.stack([read_img(path + f, dim, colspace) for f in os.listdir(path)], axis=0)\n",
    "    y = np.full(x.shape[0], color)\n",
    "    return (x, y)\n",
    "\n",
    "def read_tl_dir(path, dim, colspace):\n",
    "    x = []\n",
    "    y = []\n",
    "    for directory, color in zip(['Red/', 'Yellow/', 'Green/'], [RED, YELLOW, GREEN]):\n",
    "        x_img, y_img = read_color(os.path.join(path, directory), color, dim, colspace)\n",
    "        x.append(x_img)\n",
    "        y.append(y_img)\n",
    "    \n",
    "    x = np.concatenate(x)\n",
    "    y = np.concatenate(y)\n",
    "    x = x.astype('float32')\n",
    "    x /= 255\n",
    "    NUM_CLASSES = 3\n",
    "    y = keras.utils.to_categorical(y, NUM_CLASSES)\n",
    "    return x, y\n",
    "    \n",
    "\n",
    "def read_train_test_tl(train_path, test_path, dim, colspace):\n",
    "    x_train, y_train = read_tl_dir(train_path, dim, colspace)\n",
    "    x_test, y_test = read_tl_dir(train_path, dim, colspace)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "train_data_dir = '../imgs/training/'\n",
    "validation_data_dir = '../imgs/validation/'\n",
    "\n",
    "x_train, y_train, x_validation, y_validation = read_train_test_tl(train_data_dir, validation_data_dir, dim=(img_height, img_width),\n",
    "                                                                  colspace='HSV')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7246, 75, 40, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7246 samples, validate on 7246 samples\n",
      "Epoch 1/25\n",
      "7246/7246 [==============================] - 5s 684us/step - loss: 1.1979 - acc: 0.4510 - val_loss: 0.7744 - val_acc: 0.7755\n",
      "Epoch 2/25\n",
      "7246/7246 [==============================] - 4s 616us/step - loss: 0.7130 - acc: 0.7219 - val_loss: 0.6096 - val_acc: 0.7804\n",
      "Epoch 3/25\n",
      "7246/7246 [==============================] - 4s 616us/step - loss: 0.6191 - acc: 0.7773 - val_loss: 0.5728 - val_acc: 0.7875\n",
      "Epoch 4/25\n",
      "7246/7246 [==============================] - 4s 617us/step - loss: 0.5993 - acc: 0.7811 - val_loss: 0.5893 - val_acc: 0.7833\n",
      "Epoch 5/25\n",
      "7246/7246 [==============================] - 4s 616us/step - loss: 0.6021 - acc: 0.7815 - val_loss: 0.5696 - val_acc: 0.7872\n",
      "Epoch 6/25\n",
      "7246/7246 [==============================] - 4s 616us/step - loss: 0.5863 - acc: 0.7876 - val_loss: 0.5591 - val_acc: 0.7890\n",
      "Epoch 7/25\n",
      "7246/7246 [==============================] - 4s 617us/step - loss: 0.5933 - acc: 0.7861 - val_loss: 0.5569 - val_acc: 0.7893\n",
      "Epoch 8/25\n",
      "7246/7246 [==============================] - 4s 618us/step - loss: 0.5788 - acc: 0.7898 - val_loss: 0.5551 - val_acc: 0.7955\n",
      "Epoch 9/25\n",
      "7246/7246 [==============================] - 4s 617us/step - loss: 0.5825 - acc: 0.7879 - val_loss: 0.5460 - val_acc: 0.7931\n",
      "Epoch 10/25\n",
      "7246/7246 [==============================] - 4s 618us/step - loss: 0.5733 - acc: 0.7951 - val_loss: 0.5454 - val_acc: 0.7959\n",
      "Epoch 11/25\n",
      "7246/7246 [==============================] - 4s 618us/step - loss: 0.5724 - acc: 0.7942 - val_loss: 0.5624 - val_acc: 0.7909\n",
      "Epoch 12/25\n",
      "7246/7246 [==============================] - 4s 619us/step - loss: 0.5704 - acc: 0.7953 - val_loss: 0.5424 - val_acc: 0.7988\n",
      "Epoch 13/25\n",
      "7246/7246 [==============================] - 4s 619us/step - loss: 0.5651 - acc: 0.7993 - val_loss: 0.5541 - val_acc: 0.7967\n",
      "Epoch 14/25\n",
      "7246/7246 [==============================] - 4s 619us/step - loss: 0.5690 - acc: 0.7953 - val_loss: 0.5511 - val_acc: 0.7970\n",
      "Epoch 15/25\n",
      "7246/7246 [==============================] - 4s 619us/step - loss: 0.5651 - acc: 0.7967 - val_loss: 0.5706 - val_acc: 0.7857\n",
      "Epoch 16/25\n",
      "7246/7246 [==============================] - 4s 620us/step - loss: 0.5610 - acc: 0.8011 - val_loss: 0.5263 - val_acc: 0.8078\n",
      "Epoch 17/25\n",
      "7246/7246 [==============================] - 4s 621us/step - loss: 0.5474 - acc: 0.8022 - val_loss: 0.5521 - val_acc: 0.7940\n",
      "Epoch 18/25\n",
      "7246/7246 [==============================] - 4s 619us/step - loss: 0.5536 - acc: 0.7963 - val_loss: 0.5283 - val_acc: 0.8093\n",
      "Epoch 19/25\n",
      "7246/7246 [==============================] - 4s 619us/step - loss: 0.5476 - acc: 0.8014 - val_loss: 0.5201 - val_acc: 0.8084\n",
      "Epoch 20/25\n",
      "7246/7246 [==============================] - 4s 620us/step - loss: 0.5648 - acc: 0.8011 - val_loss: 0.5304 - val_acc: 0.8050\n",
      "Epoch 21/25\n",
      "7246/7246 [==============================] - 5s 621us/step - loss: 0.5564 - acc: 0.8024 - val_loss: 0.5295 - val_acc: 0.8118\n",
      "Epoch 22/25\n",
      "7246/7246 [==============================] - 4s 620us/step - loss: 0.5405 - acc: 0.8062 - val_loss: 0.5171 - val_acc: 0.8073\n",
      "Epoch 23/25\n",
      "7246/7246 [==============================] - 4s 620us/step - loss: 0.5458 - acc: 0.8015 - val_loss: 0.5632 - val_acc: 0.8038\n",
      "Epoch 24/25\n",
      "7246/7246 [==============================] - 4s 620us/step - loss: 0.5373 - acc: 0.8083 - val_loss: 0.5251 - val_acc: 0.8061\n",
      "Epoch 25/25\n",
      "7246/7246 [==============================] - 4s 620us/step - loss: 0.5341 - acc: 0.8069 - val_loss: 0.5020 - val_acc: 0.8130\n",
      "Test loss: 0.50201258410448\n",
      "Test accuracy: 0.8130002760308045\n"
     ]
    }
   ],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 3, img_width, img_height)\n",
    "    x_validation = x_validation.reshape(x_validation.shape[0], 3, img_width, img_height)\n",
    "    input_shape = (3, img_width, img_heigth)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_width, img_height, 3)\n",
    "    x_validation = x_validation.reshape(x_validation.shape[0], img_width, img_height, 3)\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_validation, y_validation))\n",
    "score = model.evaluate(x_validation, y_validation, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
